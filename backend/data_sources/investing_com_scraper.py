"""
Investing.com Economic Calendar Scraper
çˆ¬å– Investing.com ç¶“æ¿Ÿæ—¥æ›†æ•¸æ“šï¼ˆå…è²»å®Œæ•´æ•¸æ“šæºï¼‰
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import time


class InvestingComScraper:
    """Investing.com ç¶“æ¿Ÿæ—¥æ›†çˆ¬èŸ²"""

    def __init__(self):
        self.base_url = "https://www.investing.com/economic-calendar/"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7',
            'Connection': 'keep-alive',
        }
        self.cache = {}
        self.cache_duration = 1800  # 30åˆ†é˜å¿«å–ï¼ˆç§’ï¼‰- å„ªåŒ–è‡ª 15åˆ†é˜

        # åœ‹å®¶ä»£ç¢¼å°æ‡‰
        self.country_map = {
            'usa': 'United States',
            'eur': 'Euro Area',
            'gbp': 'United Kingdom',
            'jpy': 'Japan',
            'cny': 'China',
            'aud': 'Australia',
            'cad': 'Canada',
            'chf': 'Switzerland',
            'nzd': 'New Zealand',
            'sek': 'Sweden',
            'nok': 'Norway',
            'dkk': 'Denmark',
            'mxn': 'Mexico',
            'thb': 'Thailand',
            'sgd': 'Singapore',
            'hkd': 'Hong Kong',
            'krw': 'South Korea',
            'inr': 'India',
            'brl': 'Brazil',
            'zar': 'South Africa'
        }

        # é‡è¦æ€§å°æ‡‰
        self.importance_map = {
            'bull1': 1,  # ä½
            'bull2': 2,  # ä¸­
            'bull3': 3   # é«˜
        }

    def scrape_calendar(self, days=14) -> pd.DataFrame:
        """
        çˆ¬å–ç¶“æ¿Ÿæ—¥æ›†æ•¸æ“š

        Args:
            days: ç²å–æœªä¾† N å¤©çš„æ•¸æ“š

        Returns:
            DataFrame with columns: Date, Country, Event, Importance, Actual, Previous, Forecast
        """
        # æª¢æŸ¥å¿«å–
        cache_key = f"calendar_{days}"
        if cache_key in self.cache:
            cached_time, cached_data = self.cache[cache_key]
            if (time.time() - cached_time) < self.cache_duration:
                print(f"âœ… ä½¿ç”¨å¿«å–æ•¸æ“šï¼ˆ{int(time.time() - cached_time)}ç§’å‰ï¼‰")
                return cached_data

        print(f"ğŸŒ æ­£åœ¨çˆ¬å– Investing.com ç¶“æ¿Ÿæ—¥æ›†ï¼ˆæœªä¾† {days} å¤©ï¼‰...")

        try:
            # ç™¼é€è«‹æ±‚
            response = requests.get(
                self.base_url,
                headers=self.headers,
                timeout=15
            )
            response.raise_for_status()

            # è§£æ HTML
            soup = BeautifulSoup(response.content, 'html.parser')

            # æŸ¥æ‰¾ç¶“æ¿Ÿæ—¥æ›†è¡¨æ ¼
            events_table = soup.find('table', {'id': 'economicCalendarData'})

            if not events_table:
                print("âŒ æœªæ‰¾åˆ°ç¶“æ¿Ÿæ—¥æ›†è¡¨æ ¼")
                return pd.DataFrame()

            # è§£æäº‹ä»¶
            events = []
            rows = events_table.find_all('tr', {'class': 'js-event-item'})

            print(f"ğŸ“Š æ‰¾åˆ° {len(rows)} å€‹äº‹ä»¶")

            for row in rows:
                event = self._parse_event_row(row)
                if event:
                    events.append(event)

            # è½‰æ›ç‚º DataFrame
            df = pd.DataFrame(events)

            if not df.empty:
                # éæ¿¾æ—¥æœŸç¯„åœï¼ˆä¿ç•™ä»Šå¤©åŠæœªä¾† N å¤©ï¼Œä½¿ç”¨æ—¥æœŸæ¯”è¼ƒè€Œéæ™‚é–“ï¼‰
                today = datetime.now().date()
                end_date = today + timedelta(days=days)

                df['Date_parsed'] = pd.to_datetime(df['Date'], errors='coerce')
                df['Date_only'] = df['Date_parsed'].dt.date
                df = df[
                    (df['Date_only'] >= today) &
                    (df['Date_only'] <= end_date)
                ]
                df = df.drop(['Date_parsed', 'Date_only'], axis=1)

            print(f"âœ… æˆåŠŸçˆ¬å– {len(df)} å€‹äº‹ä»¶")

            # æ›´æ–°å¿«å–
            self.cache[cache_key] = (time.time(), df)

            return df

        except Exception as e:
            print(f"âŒ çˆ¬å–å¤±æ•—: {e}")
            return pd.DataFrame()

    def _parse_event_row(self, row) -> Optional[Dict]:
        """
        è§£æå–®å€‹äº‹ä»¶è¡Œ

        Args:
            row: BeautifulSoup row element

        Returns:
            Event dictionary or None
        """
        try:
            # æå–æ™‚é–“
            time_cell = row.find('td', {'class': 'time'})
            event_time = time_cell.text.strip() if time_cell else '00:00'

            # æå–åœ‹å®¶ï¼ˆå¾ flag span çš„ title å±¬æ€§ï¼‰
            flag_cell = row.find('td', {'class': 'flagCur'})
            country = 'Unknown'
            if flag_cell:
                flag_span = flag_cell.find('span', {'class': 'ceFlags'})
                if flag_span and flag_span.get('title'):
                    country = flag_span['title']

            # æå–äº‹ä»¶åç¨±å’Œé€£çµ
            event_cell = row.find('td', {'class': 'event'})
            event_name = event_cell.text.strip() if event_cell else ''
            event_url = ''

            if event_cell:
                event_link = event_cell.find('a')
                if event_link and event_link.get('href'):
                    # Investing.com ç›¸å°é€£çµè½‰çµ•å°é€£çµ
                    event_url = f"https://www.investing.com{event_link['href']}"

            if not event_name:
                return None

            # æå–é‡è¦æ€§ï¼ˆè¨ˆç®— bull åœ–æ¨™æ•¸é‡ï¼‰
            importance_cell = row.find('td', {'class': 'sentiment'})
            importance = 1
            if importance_cell:
                # è¨ˆç®—å¡«æ»¿çš„ bull åœ–æ¨™æ•¸é‡ï¼ˆ1-3 é¡†æ˜Ÿï¼‰
                bull_icons = importance_cell.find_all('i', {'class': 'grayFullBullishIcon'})
                importance = len(bull_icons) if bull_icons else 1

            # æå–å¯¦éš›å€¼ï¼ˆä½¿ç”¨ class é¸æ“‡å™¨ï¼‰
            actual_cell = row.find('td', {'class': 'bold'})
            actual = actual_cell.text.strip() if actual_cell else ''

            # æå–é æ¸¬å€¼
            forecast_cell = row.find('td', {'class': 'fore'})
            forecast = forecast_cell.text.strip() if forecast_cell else ''

            # æå–å‰å€¼
            previous_cell = row.find('td', {'class': 'prev'})
            previous = previous_cell.text.strip() if previous_cell else ''

            # æå–æ—¥æœŸï¼ˆå¾ data-event-datetime å±¬æ€§ï¼‰
            event_datetime = row.get('data-event-datetime', '')
            if event_datetime:
                # æ ¼å¼: "2025/10/30 08:00:00"
                try:
                    dt = datetime.strptime(event_datetime, '%Y/%m/%d %H:%M:%S')
                    date_str = dt.isoformat()
                except:
                    date_str = datetime.now().isoformat()
            else:
                # ä½¿ç”¨ä»Šå¤©æ—¥æœŸ + æ™‚é–“
                today = datetime.now()
                try:
                    time_parts = event_time.split(':')
                    dt = today.replace(hour=int(time_parts[0]), minute=int(time_parts[1]), second=0)
                    date_str = dt.isoformat()
                except:
                    date_str = today.isoformat()

            return {
                'Date': date_str,
                'Country': country,
                'Event': event_name,
                'EventURL': event_url,
                'Importance': importance,
                'Actual': actual,
                'Previous': previous,
                'Forecast': forecast
            }

        except Exception as e:
            print(f"âš ï¸  è§£æäº‹ä»¶å¤±æ•—: {e}")
            return None


# ========== æ¸¬è©¦ä»£ç¢¼ ==========

def test_investing_scraper():
    """æ¸¬è©¦ Investing.com çˆ¬èŸ²"""
    print("=== Investing.com çˆ¬èŸ²æ¸¬è©¦ ===\n")

    scraper = InvestingComScraper()
    df = scraper.scrape_calendar(days=7)

    if not df.empty:
        print(f"\nâœ… æˆåŠŸçˆ¬å– {len(df)} å€‹äº‹ä»¶")
        print(f"\nå‰ 5 å€‹äº‹ä»¶:")
        print(df.head())

        print(f"\næ•¸æ“šæ¬„ä½: {list(df.columns)}")
        print(f"\nåœ‹å®¶åˆ†å¸ƒ:")
        print(df['Country'].value_counts())
        print(f"\né‡è¦æ€§åˆ†å¸ƒ:")
        print(df['Importance'].value_counts())
    else:
        print("âŒ æœªç²å–åˆ°æ•¸æ“š")


if __name__ == "__main__":
    test_investing_scraper()
